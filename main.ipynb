{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Framing\n",
    "\n",
    "The goal of this project is to develop an image classification model that can accurately predict the name of Cricketers from images uploaded to a website. The dataset contains images of Nepalese cricketers, and the task is to classify each image into one of the predefined categories.\n",
    "\n",
    "To achieve this, we will follow a series of steps such as data preprocessing, data cleaning, and data exploration to prepare the data for modeling. We will then perform feature engineering to extract relevant features from the images and select the best model and hyperparameters to train the classification model.\n",
    "\n",
    "Once the model is trained, we will evaluate its performance on a test dataset and fine-tune it as necessary. Finally, we will integrate the model into a web application, allowing users to upload images to the website and receive predictions about the Nepalese cricketer in the image.\n",
    "\n",
    "The success of this project will be determined by the accuracy and efficiency of the model in classifying the images, as well as the smooth and user-friendly interface of the web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Aquisition\n",
    "To acquire the necessary data for my image classification project, I performed web scraping of Cricketers images from Google. I achieved this by utilizing a [Python script](web_scrapping.py) that implements web scraping techniques to download images of Cristiano Ronaldo from Google. The script imports essential libraries such as requests, os, time, and BeautifulSoup.\n",
    "\n",
    "To begin, the search query and the desired number of images to download are defined, along with the URL of the search results page. The script then executes a GET request to the URL, obtains the HTML content using the requests library, and parses the content with the BeautifulSoup library to locate all image tags.\n",
    "\n",
    "In case a folder with the search query's name does not already exist, the script uses the os.mkdir() function to create a new folder. The script proceeds to iterate through the image tags and downloads each image to the folder using the with open() statement. To prevent Google from blocking further requests, the script introduces a delay of 10 seconds between each 20 requests using the time.sleep() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./dataset/\"\n",
    "path_cropped_data = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = [file.path for file in os.scandir(path_data) if file.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_cropped_data):\n",
    "     shutil.rmtree(path_cropped_data)\n",
    "os.mkdir(path_cropped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohit_Sharma\n",
      "Generating cropped images in folder:  ./dataset/cropped/Rohit_Sharma\n",
      "Ab_De_Villiers\n",
      "Generating cropped images in folder:  ./dataset/cropped/Ab_De_Villiers\n",
      "MS_Dhoni\n",
      "Generating cropped images in folder:  ./dataset/cropped/MS_Dhoni\n",
      "Sachin_Tendulkar\n",
      "Generating cropped images in folder:  ./dataset/cropped/Sachin_Tendulkar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virat_Kholi\n",
      "Generating cropped images in folder:  ./dataset/cropped/Virat_Kholi\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    \n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_cropped_data+ celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "                \n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name \n",
    "            \n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    celebrity_file_names_dict[celebrity_name] = file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2d(imArray, mode='haar', level=1):\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255\n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode)\n",
    "    imArray_H *= 255\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None or img.size == 0:\n",
    "            continue\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 4096, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).astype(float)\n",
    "y = np.array(y).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 4096)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], 4096)\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 327.4070 - accuracy: 0.0851\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 122.2424 - accuracy: 0.3670\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 61.8610 - accuracy: 0.3777\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 57.1246 - accuracy: 0.4840\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 38.6741 - accuracy: 0.6489\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 26.9196 - accuracy: 0.5213\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15.3244 - accuracy: 0.6862\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.1948 - accuracy: 0.7819\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6.4959 - accuracy: 0.7553\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.4493 - accuracy: 0.8085\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.6569 - accuracy: 0.8511\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 4.6771 - accuracy: 0.8564\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.9702 - accuracy: 0.7606\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 9.1462 - accuracy: 0.7713\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.5819 - accuracy: 0.8032\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.8950 - accuracy: 0.8138\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 7.1789 - accuracy: 0.8351\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 8.8013 - accuracy: 0.7819\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 5.1640 - accuracy: 0.7766\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 3.0203 - accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc47b7ea1c0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "neural_network = keras.Sequential([\n",
    "    keras.layers.Reshape((64, 64, 1), input_shape=X.shape[1:]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(len(y), activation='softmax')\n",
    "])\n",
    "\n",
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "neural_network.fit(X, y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 3.8570 - accuracy: 0.8298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8569862842559814, 0.8297872543334961]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        },\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.728307</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.505974</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.723186</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.728307   \n",
       "1        random_forest    0.505974   \n",
       "2  logistic_regression    0.723186   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X, y)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.3624 - accuracy: 0.1348\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 230.6536 - accuracy: 0.1915\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 108.5995 - accuracy: 0.3901\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 97.8030 - accuracy: 0.4326\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.0759 - accuracy: 0.4539\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.4010 - accuracy: 0.4823\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.3400 - accuracy: 0.5957\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.3546 - accuracy: 0.7021\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2032 - accuracy: 0.7376\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.0009 - accuracy: 0.7305\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2698 - accuracy: 0.7801\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6984 - accuracy: 0.8156\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2318 - accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0009 - accuracy: 0.9291\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3408 - accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6221 - accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.9504\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7296 - accuracy: 0.8652\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5724 - accuracy: 0.9149\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9085 - accuracy: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4c876bf10>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = keras.Sequential([\n",
    "    keras.layers.Reshape((64, 64, 1), input_shape=X.shape[1:]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(len(y), activation='softmax')\n",
    "])\n",
    "\n",
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "neural_network.fit(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 28.4965 - accuracy: 0.5319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28.496503829956055, 0.5319148898124695]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Monitoring and Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
